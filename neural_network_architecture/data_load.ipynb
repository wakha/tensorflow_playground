{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a473339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import gzip\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3324dcf4",
   "metadata": {},
   "source": [
    "Let's start by getting familiar with the data you'll be using, the Fashion MNIST dataset. This dataset contains 70,000 grayscale images of articles of clothing: 60,000 images for training and 10,000 for testing. The images are square and contain 28 Ã— 28 = 784 pixels, where each pixel is represented by a value between 0 and 255. Each of these images is associated with a label, which is an integer between 0 and 9 that classifies the article of clothing. The following dictionary helps us understand the clothing categories corresponding to these integer labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06701db",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "  0: 'T-Shirt',\n",
    "  1: 'Trouser',\n",
    "  2: 'Pullover',\n",
    "  3: 'Dress',\n",
    "  4: 'Coat',\n",
    "  5: 'Sandal',\n",
    "  6: 'Shirt',\n",
    "  7: 'Sneaker',\n",
    "  8: 'Bag',\n",
    "  9: 'Ankle Boot',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec72d2ac",
   "metadata": {},
   "source": [
    "Loadind data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4073f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5fb0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def read_images(path: str, image_size: int, num_items: int) -> np.ndarray:\n",
    "#  with gzip.open(path, 'rb') as file:\n",
    "#    data = np.frombuffer(file.read(), np.uint8, offset=16)\n",
    "#    data = data.reshape(num_items, image_size, image_size)\n",
    "#  return data\n",
    "\n",
    "#def read_labels(path: str, num_items: int) -> np.ndarray:\n",
    "#  with gzip.open(path, 'rb') as file:\n",
    "#    data = np.frombuffer(file.read(num_items + 8), np.uint8, offset=8)\n",
    "#    data = data.astype(np.int64)\n",
    "#  return data\n",
    "\n",
    "#image_size = 28\n",
    "#num_train = 60000\n",
    "#num_test = 10000\n",
    "\n",
    "#training_images = read_images('data/FashionMNIST/raw/train-images-idx3-ubyte.gz', image_size, num_train)\n",
    "#test_images = read_images('data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz', image_size, num_test)\n",
    "#training_labels = read_labels('data/FashionMNIST/raw/train-labels-idx1-ubyte.gz', num_train)\n",
    "#test_labels = read_labels('data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz', num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024c9962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols = 3\n",
    "rows = 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "  sample_idx = random.randint(0, len(training_images))\n",
    "  image = training_images[sample_idx]\n",
    "  label = training_labels[sample_idx]\n",
    "  figure.add_subplot(rows, cols, i)\n",
    "  plt.title(labels_map[label])\n",
    "  plt.axis('off')\n",
    "  plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de86ea85",
   "metadata": {},
   "source": [
    "Wrap the data into tf.data.Dataset that handles large datasets better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0bdfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((training_images, training_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479877c7",
   "metadata": {},
   "source": [
    "You saw earlier that each pixel of the image is represented by an unsigned int. In machine learning, you generally want the pixel values of your training data to be floating-point numbers between 0 and 1, so you convert them in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(lambda image, label: (float(image) / 255.0, label))\n",
    "test_dataset = test_dataset.map(lambda image, label: (float(image) / 255.0, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b073e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.as_numpy_iterator().next()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6788833",
   "metadata": {},
   "source": [
    "As expected, the pixel values are now floating-point numbers between 0 and 1.\n",
    "\n",
    "Now that you have a Dataset, you can no longer index it the same way as a NumPy array. Instead, you get an iterator by calling the as_numpy_iterator method, and advance it by calling its next method. At this point, you have a tuple containing an image and the corresponding label, so you can get the element at index 0 to inspect the image.\n",
    "\n",
    "Finally, tell the Dataset to give us batches of data of size 64, and shuffle the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb5114",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataset = train_dataset.batch(batch_size).shuffle(500)\n",
    "test_dataset = test_dataset.batch(batch_size).shuffle(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298c6f3a",
   "metadata": {},
   "source": [
    "By specifying the batch size, you're telling the Dataset that when you iterate over it, you want to receive not one, but a batch of 64 items instead. If you print the length of the first item returned by the iterator, you can see that you get 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb160339",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset.as_numpy_iterator().next()[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
